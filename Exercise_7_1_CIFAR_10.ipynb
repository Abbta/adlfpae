{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abbta/adlfpae/blob/main/Exercise_7_1_CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIC4ypzrTXj7"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "layers = tf.keras.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdB6l-5s-7cJ"
      },
      "source": [
        "The code block below defines a few helper functions to visualize the results. You do not need to touch them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCxC5DPEkGLn"
      },
      "source": [
        "def plot_examples(X, Y, n=10):\n",
        "    \"\"\" Plot the first n examples for each of the 10 classes in the CIFAR dataset X, Y \"\"\"\n",
        "    fig, axes = plt.subplots(n, 10, figsize=(10, n))\n",
        "    for l in range(10):\n",
        "        axes[0, l].set_title(cifar10_labels[l], fontsize=\"smaller\")\n",
        "        m = np.squeeze(Y) == l  # boolean mask: True for all images of label l\n",
        "        for i in range(n):\n",
        "            image = X[m][i].astype(\"uint8\")  # imshow expects uint8\n",
        "            ax = axes[i, l]\n",
        "            ax.imshow(image, origin=\"upper\")\n",
        "            ax.set(xticks=[], yticks=[])\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "def plot_prediction(X, Y, Y_predict):\n",
        "    \"\"\"\n",
        "    Plot image X along with predicted probabilities Y_predict.\n",
        "    X: CIFAR image, shape = (32, 32, 3)\n",
        "    Y: CIFAR label, one-hot encoded, shape = (10)\n",
        "    Y_predict: predicted probabilities, shape = (10)\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "    # plot image\n",
        "    ax1.imshow(X.astype(\"uint8\"), origin=\"upper\")\n",
        "    ax1.set(xticks=[], yticks=[])\n",
        "\n",
        "    # plot probabilities\n",
        "    ax2.barh(np.arange(10), Y_predict, align=\"center\")\n",
        "    ax2.set(xlim=(0, 1), xlabel=\"Score\", yticks=[])\n",
        "    for i in range(10):\n",
        "        c = \"red\" if (i == np.argmax(Y)) else \"black\"\n",
        "        ax2.text(0.05, i, cifar10_labels[i].capitalize(), ha=\"left\", va=\"center\", color=c)\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion(Y_true, Y_predict):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix\n",
        "    Y_true:    array of true classifications (0-9), shape = (N)\n",
        "    Y_predict: array of predicted classifications (0-9), shape = (N)\n",
        "    \"\"\"\n",
        "    C = np.histogram2d(Y_true, Y_predict, bins=np.linspace(-0.5, 9.5, 11))[0]\n",
        "    Cn = C / np.sum(C, axis=1)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(Cn, interpolation=\"nearest\", vmin=0, vmax=1, cmap=plt.cm.YlGnBu)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"prediction\")\n",
        "    plt.ylabel(\"truth\")\n",
        "    plt.xticks(range(10), cifar10_labels, rotation=\"vertical\")\n",
        "    plt.yticks(range(10), cifar10_labels)\n",
        "    for x in range(10):\n",
        "        for y in range(10):\n",
        "            plt.annotate(\"%i\" % C[x, y], xy=(y, x), ha=\"center\", va=\"center\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_hToNncTkT0"
      },
      "source": [
        "First we load and preprocess CIFAR-10 data. The imagages are 32x32 pixels and have three color channels (red, green blue)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0tpFVjwTklD",
        "outputId": "ea3b4ecb-78a9-4433-98b0-229c0f720b2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# X: images, Y: labels\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(\"images, shape = \", x_train.shape)\n",
        "print(\"labels, shape = \", y_train.shape)\n",
        "\n",
        "cifar10_labels = np.array([\n",
        "    'airplane',\n",
        "    'automobile',\n",
        "    'bird',\n",
        "    'cat',\n",
        "    'deer',\n",
        "    'dog',\n",
        "    'frog',\n",
        "    'horse',\n",
        "    'ship',\n",
        "    'truck'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n",
            "images, shape =  (50000, 32, 32, 3)\n",
            "labels, shape =  (50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsrAdqcbBaMS"
      },
      "source": [
        "# Hint: To plot example images, you can use the plot examples function\n",
        "# plot_examples(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzsaCtB_ZQpn"
      },
      "source": [
        "# convert labels (\"0\"-\"9\") to one-hot encodings, \"0\" = (1, 0, ... 0) and so on\n",
        "y_train_onehot = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test_onehot = tf.keras.utils.to_categorical(y_test, 10)[:8000]\n",
        "y_valid_onehot = tf.keras.utils.to_categorical(y_test, 10)[8000:]\n",
        "\n",
        "# Hint: normalize the data\n",
        "# Hint: use 20% of the training data for validation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK4hJmraZX9k"
      },
      "source": [
        "We start with a fully connected network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6fLIMDOZaSp"
      },
      "source": [
        "# ----------------------------------------------------------\n",
        "# Define model\n",
        "# ----------------------------------------------------------\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        layers.Flatten(input_shape=(32, 32, 3)),  # (32,32,3) --> (3072)\n",
        "        # this time the flatten operation is directly integrated into the network\n",
        "        # structure so that we can use the same input data later for a convolutional neural network.\n",
        "        ...\n",
        "        # Hint: remember that the output layer should have 10 nodes with a softmax activation\n",
        "    ],\n",
        "    name=\"nn\",\n",
        ")\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxFRmIDuZjA8"
      },
      "source": [
        "# ----------------------------------------------------------\n",
        "# Training\n",
        "# ----------------------------------------------------------\n",
        "model.compile(\n",
        "    ...\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ...\n",
        "    batch_size=...,\n",
        "    epochs=20, # train at least for 20 epochs\n",
        "    verbose=2,\n",
        "    validation_data=(x_valid_norm, y_valid_onehot),\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger(\"history_{}.csv\".format(model.name))],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKDrWN9nZqIP"
      },
      "source": [
        "# ----------------------------------------------------------\n",
        "# Plots\n",
        "# ----------------------------------------------------------\n",
        "# training curves\n",
        "history = np.genfromtxt(\"history_{}.csv\".format(model.name), delimiter=\",\", names=True)\n",
        "\n",
        "\n",
        "# Hint: this is how you can plot the confusion matrix.\n",
        "# calculate predictions for test set\n",
        "y_predict = model.predict(..., batch_size=128)\n",
        "\n",
        "# convert back to class labels (0-9)\n",
        "y_predict_cl = np.argmax(y_predict, axis=1)\n",
        "y_test_cl = np.argmax(y_test_onehot, axis=1)\n",
        "\n",
        "# plot confusion matrix\n",
        "plot_confusion(y_test_cl, y_predict_cl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HF58Clib-ZL"
      },
      "source": [
        "# Task: plot a few examples of correctly and incorrectly classified images.\n",
        "# Hint: First find the indices of correctly and incorrectly classified images:\n",
        "m = y_predict_cl == y_test_cl\n",
        "i0 = np.arange(8000)[~m]  # misclassified images\n",
        "i1 = np.arange(8000)[m]  # correctly classified images\n",
        "\n",
        "# original (unnormalized) test images\n",
        "x_test = x_test[:8000]\n",
        "\n",
        "# Hint: Now you can use the `plot_prediction` function to plot the images:\n",
        "# plot first 10 false classifications\n",
        "for i in i0[0:10]:\n",
        "    plot_prediction(x_test[i], y_test_onehot[i], y_predict[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfxphxaYaB1E"
      },
      "source": [
        "**CNN**\n",
        "In the second part of this exercise, classify the images with a CNN.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmApnvXvVdLZ"
      },
      "source": [
        "# Hint: this code snipped shows how to define convolution and maxpooling layers. For more information see\n",
        "# https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "# https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        layers.Conv2D(16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        ... # add additional convolution layer and max pooling layer here,\n",
        "        layers.Flatten(),\n",
        "        ... # add dropout and output layer\n",
        "    ],\n",
        "    name=\"cnn\",\n",
        ")\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogdq9XKDVlxw"
      },
      "source": [
        "# ----------------------------------------------------------\n",
        "# Training\n",
        "# ----------------------------------------------------------\n",
        "model.compile(\n",
        "...\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ...\n",
        "    batch_size=..,\n",
        "    epochs=40,\n",
        "    validation_data=(x_valid_norm, y_valid_onehot),\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger(\"history_{}.csv\".format(model.name))],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}