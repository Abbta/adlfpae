{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abbta/adlfpae/blob/main/Exercise_10_real_time_noise_rejection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKNPAywdme7l"
      },
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIiiIfjtornz"
      },
      "source": [
        "You can estimate how fast a network prediction can be calculated by calculating the number of floating point operations performed in the network. This function is a handy tool to do it. Use it like this `print(get_flops(my_model))` where `my_model` is your KERAS neural network model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgRMMUD3M95T"
      },
      "source": [
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
        "import tensorflow as tf\n",
        "######################################Calculate FLOPS##########################################\n",
        "def get_flops(model):\n",
        "    '''\n",
        "    Calculate FLOPS\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : tf.keras.Model\n",
        "        Model for calculating FLOPS.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    flops.total_float_ops : int\n",
        "        Calculated FLOPS for the model\n",
        "    '''\n",
        "\n",
        "    batch_size = 1\n",
        "\n",
        "    real_model = tf.function(model).get_concrete_function(tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype))\n",
        "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
        "\n",
        "    run_meta = tf.compat.v1.RunMetadata()\n",
        "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,run_meta=run_meta, cmd='op', options=opts)\n",
        "    return flops.total_float_ops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc_NkUbqpAhA"
      },
      "source": [
        "Downloading the data (1 signal data file and 5 noise data files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xo0M2DsmvEB"
      },
      "source": [
        "# download data file that contains signal events\n",
        "if not os.path.exists(\"trimmed100_data_signal_3.6SNR_1ch_0000.npy\"):\n",
        "  !gdown https://drive.google.com/uc?id=1t-1icmiJ8Nwu1dm_USIc_W13B68QDwqq\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8glqzapEpEnW"
      },
      "source": [
        "# download data file that contains noise events\n",
        "if not os.path.exists(\"trimmed100_data_noise_3.6SNR_1ch_0000.npy\"):\n",
        "  !gdown https://drive.google.com/uc?id=14Aff8wf-e1qTQwWU0I-PkrbdbdtS6dei\n",
        "if not os.path.exists(\"trimmed100_data_noise_3.6SNR_1ch_0001.npy\"):\n",
        "  !gdown https://drive.google.com/uc?id=1EkhWgOXOvaK74JiWPOxt6DUE4S5NGYrT\n",
        "if not os.path.exists(\"trimmed100_data_noise_3.6SNR_1ch_0002.npy\"):\n",
        "  !gdown https://drive.google.com/uc?id=1BSPvbNOJ2kG7p3ImsVekz4jwXUqlhLRd\n",
        "if not os.path.exists(\"trimmed100_data_noise_3.6SNR_1ch_0003.npy\"):\n",
        "  !gdown https://drive.google.com/uc?id=1xoTjcJd762XUAP0I7Ukv0y2go6ZwTmIa\n",
        "if not os.path.exists(\"trimmed100_data_noise_3.6SNR_1ch_0004.npy\"):\n",
        "  !gdown https://drive.google.com/uc?id=1CAmatsbjLmhefxvoH4fr7O-8pGA5p4KY\n",
        "if not os.path.exists(\"trimmed100_data_noise_3.6SNR_1ch_0005.npy\"):\n",
        "  !gdown https://drive.google.com/uc?id=1lX4M1t8W4zg0wVXA4HYUlnFGU3nMYPGx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL6m29SSpN8N"
      },
      "source": [
        "Load the data into memory and combine it into one array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcdJTLahmpoS"
      },
      "source": [
        "# load signal and noise data set into memory\n",
        "noise = np.load(\"trimmed100_data_noise_3.6SNR_1ch_0000.npy\")\n",
        "for i in range(1,5):\n",
        "  noise = np.vstack((noise,np.load(f\"trimmed100_data_noise_3.6SNR_1ch_000{i}.npy\")))\n",
        "signal = np.load(\"trimmed100_data_signal_3.6SNR_1ch_0000.npy\")\n",
        "n_classes = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn0Cdwcvmt3L"
      },
      "source": [
        "# combine noise and signal data set\n",
        "x = np.vstack((noise, signal))\n",
        "print(x.shape)\n",
        "# in case you want to train a CNN, you need to add an empty dimension to the array\n",
        "# which you can do via x = np.expand_dims(x, axis=-1)\n",
        "\n",
        "# define labels. As we have only two categories, we don't use one-hot encoding\n",
        "# but can just use \"0\" for noise and \"1\" for signal.\n",
        "y = np.ones(len(x))\n",
        "y[:len(noise)] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v2qlrszpUI0"
      },
      "source": [
        "Currently, the training data first contains all noise events and then only signal events. This is not optimal, especially because Keras will pick the last X% of the data set for the validation data (which would mean we train only on noise and then validate with signal, which does not make much sense). Therefore, we randomly shuffle the dataset. Important: The x and y arrays need to be shuffled identicially as in the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8oZlImrnHB7"
      },
      "source": [
        "# shuffel the data\n",
        "shuffle = np.arange(x.shape[0], dtype=int)\n",
        "np.random.shuffle(shuffle)\n",
        "x = x[shuffle]\n",
        "y = y[shuffle]\n",
        "\n",
        "# to still be able to identify the signal events you can do\n",
        "smask = y == 1\n",
        "# then you can get all signal events via `x[smask]`\n",
        "# and all noise events via `x[~smask]`\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdVeY7TYzj7P"
      },
      "source": [
        "# plot a few signal events\n",
        "for trace in x[smask][:5]:\n",
        "  fig, ax = plt.subplots(1, 1)\n",
        "  ax.plot(trace)\n",
        "  fig.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}