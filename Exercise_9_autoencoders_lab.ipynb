{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Abbta/adlfpae/blob/main/Exercise_9_autoencoders_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwK4CPGb7O84"
   },
   "source": [
    "## Autoencoders Lab\n",
    "#### visualizing HapMap phase 3 populations\n",
    "\n",
    "**This is a solution template. Every chunk of code requiring your input will begin with the # TASK comment and all places where you should fill-in with your code are marked by ellipsis (...).**\n",
    "\n",
    "### Stage 0 &mdash; getting the data\n",
    "\n",
    "First, we will download the data from the linked Dropbox account. The code is hidden as it is not super important here. Double-click below if you are curious to see it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VR5Tn0OA6S-L"
   },
   "outputs": [],
   "source": [
    "#@title Load raw data. Double click to see the code. { display-mode: \"form\" }\n",
    "\n",
    "!wget https://www.dropbox.com/s/g7862q1l4ls9z3x/autosomal_5k_matrix.csv\n",
    "!wget https://www.dropbox.com/s/3lv0062dw20qdqg/autosomal_5k_phenos.csv\n",
    "!wget https://www.dropbox.com/s/6nzrusxkm536a5j/autosomal_5k_kinship.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVM1F-zSDhs8"
   },
   "source": [
    "Now, we will load the data and make sure they look as expected. Note, the genotypes per individual (row) are encoded as the count of minor alleles and thus can take values `gt = {0, 1, 2}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2_v8Lv8ZVu0v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         rs416967  rs17013842  rs13052452  rs11049986  rs10994341  rs1504289  \\\n",
      "NA19919         2           1           0           1           1          0   \n",
      "NA19916         1           0           0           1           1          0   \n",
      "NA19835         0           0           1           1           0          1   \n",
      "NA20282         1           1           0           1           0          0   \n",
      "NA19703         0           0           0           0           1          1   \n",
      "...           ...         ...         ...         ...         ...        ...   \n",
      "NA19119         1           0           1           0           1          1   \n",
      "NA18860         1           0           0           1           1          0   \n",
      "NA19207         2           0           0           0           1          0   \n",
      "NA19103         1           0           1           0           0          0   \n",
      "NA19099         0           0           1           1           0          1   \n",
      "\n",
      "         rs882529  rs3885937  rs537330  rs9372090  ...  rs1558766  rs7818288  \\\n",
      "NA19919         0          1         1          1  ...          0          1   \n",
      "NA19916         1          1         2          1  ...          0          0   \n",
      "NA19835         0          2         2          1  ...          0          1   \n",
      "NA20282         0          0         1          1  ...          0          0   \n",
      "NA19703         0          0         0          2  ...          0          1   \n",
      "...           ...        ...       ...        ...  ...        ...        ...   \n",
      "NA19119         1          1         1          2  ...          0          0   \n",
      "NA18860         0          1         2          1  ...          1          1   \n",
      "NA19207         1          1         2          0  ...          0          0   \n",
      "NA19103         1          1         2          1  ...          0          0   \n",
      "NA19099         0          1         0          0  ...          0          1   \n",
      "\n",
      "         rs1051685  rs11223492  rs789492  rs6557516  rs7313246  rs317892  \\\n",
      "NA19919          0           0         1          0          1         1   \n",
      "NA19916          0           0         0          1          1         1   \n",
      "NA19835          0           0         0          0          2         2   \n",
      "NA20282          0           0         0          0          1         2   \n",
      "NA19703          1           0         1          1          1         1   \n",
      "...            ...         ...       ...        ...        ...       ...   \n",
      "NA19119          0           0         0          0          0         1   \n",
      "NA18860          0           0         0          0          1         0   \n",
      "NA19207          0           0         0          1          0         1   \n",
      "NA19103          0           0         0          0          2         1   \n",
      "NA19099          0           0         0          0          1         1   \n",
      "\n",
      "         rs11937009  rs2806497  \n",
      "NA19919           1          0  \n",
      "NA19916           1          0  \n",
      "NA19835           0          0  \n",
      "NA20282           0          0  \n",
      "NA19703           2          0  \n",
      "...             ...        ...  \n",
      "NA19119           0          0  \n",
      "NA18860           0          1  \n",
      "NA19207           1          0  \n",
      "NA19103           2          0  \n",
      "NA19099           0          0  \n",
      "\n",
      "[1184 rows x 5000 columns]\n",
      "              id  sex   FID      dad      mom  pheno population\n",
      "NA19919  NA19919    1  2427  NA19908  NA19909      0        ASW\n",
      "NA19916  NA19916    1  2431        0        0      0        ASW\n",
      "NA19835  NA19835    0  2424        0        0      0        ASW\n",
      "NA20282  NA20282    0  2469        0        0      0        ASW\n",
      "NA19703  NA19703    1  2368        0        0      0        ASW\n",
      "...          ...  ...   ...      ...      ...    ...        ...\n",
      "NA19119  NA19119    1  Y060        0        0      0        YRI\n",
      "NA18860  NA18860    1  Y012  NA18859  NA18858      0        YRI\n",
      "NA19207  NA19207    1  Y051        0        0      0        YRI\n",
      "NA19103  NA19103    1  Y042  NA19101  NA19102      0        YRI\n",
      "NA19099  NA19099    0  Y105        0        0      0        YRI\n",
      "\n",
      "[1184 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"autosomal_5k_matrix.csv\", header=0, index_col=0)\n",
    "pheno = pd.read_csv(\"autosomal_5k_phenos.csv\", header=0, index_col=0)\n",
    "\n",
    "print(data)\n",
    "print(pheno)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9bJbHksPJ3q"
   },
   "source": [
    "Now, we will create a dictionary and re-name our populations so that the names are a bit more informative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "iRDgDj-H7mZK",
    "outputId": "bd521e6d-b244-4122-be58-c88b590695e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>FID</th>\n",
       "      <th>dad</th>\n",
       "      <th>mom</th>\n",
       "      <th>pheno</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NA19919</th>\n",
       "      <td>NA19919</td>\n",
       "      <td>1</td>\n",
       "      <td>2427</td>\n",
       "      <td>NA19908</td>\n",
       "      <td>NA19909</td>\n",
       "      <td>0</td>\n",
       "      <td>African ancestry in SW USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19916</th>\n",
       "      <td>NA19916</td>\n",
       "      <td>1</td>\n",
       "      <td>2431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>African ancestry in SW USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19835</th>\n",
       "      <td>NA19835</td>\n",
       "      <td>0</td>\n",
       "      <td>2424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>African ancestry in SW USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA20282</th>\n",
       "      <td>NA20282</td>\n",
       "      <td>0</td>\n",
       "      <td>2469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>African ancestry in SW USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19703</th>\n",
       "      <td>NA19703</td>\n",
       "      <td>1</td>\n",
       "      <td>2368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>African ancestry in SW USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19119</th>\n",
       "      <td>NA19119</td>\n",
       "      <td>1</td>\n",
       "      <td>Y060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yoruba in Ibadan Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA18860</th>\n",
       "      <td>NA18860</td>\n",
       "      <td>1</td>\n",
       "      <td>Y012</td>\n",
       "      <td>NA18859</td>\n",
       "      <td>NA18858</td>\n",
       "      <td>0</td>\n",
       "      <td>Yoruba in Ibadan Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19207</th>\n",
       "      <td>NA19207</td>\n",
       "      <td>1</td>\n",
       "      <td>Y051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yoruba in Ibadan Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19103</th>\n",
       "      <td>NA19103</td>\n",
       "      <td>1</td>\n",
       "      <td>Y042</td>\n",
       "      <td>NA19101</td>\n",
       "      <td>NA19102</td>\n",
       "      <td>0</td>\n",
       "      <td>Yoruba in Ibadan Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA19099</th>\n",
       "      <td>NA19099</td>\n",
       "      <td>0</td>\n",
       "      <td>Y105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yoruba in Ibadan Nigeria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1184 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sex   FID      dad      mom  pheno  \\\n",
       "NA19919  NA19919    1  2427  NA19908  NA19909      0   \n",
       "NA19916  NA19916    1  2431        0        0      0   \n",
       "NA19835  NA19835    0  2424        0        0      0   \n",
       "NA20282  NA20282    0  2469        0        0      0   \n",
       "NA19703  NA19703    1  2368        0        0      0   \n",
       "...          ...  ...   ...      ...      ...    ...   \n",
       "NA19119  NA19119    1  Y060        0        0      0   \n",
       "NA18860  NA18860    1  Y012  NA18859  NA18858      0   \n",
       "NA19207  NA19207    1  Y051        0        0      0   \n",
       "NA19103  NA19103    1  Y042  NA19101  NA19102      0   \n",
       "NA19099  NA19099    0  Y105        0        0      0   \n",
       "\n",
       "                         population  \n",
       "NA19919  African ancestry in SW USA  \n",
       "NA19916  African ancestry in SW USA  \n",
       "NA19835  African ancestry in SW USA  \n",
       "NA20282  African ancestry in SW USA  \n",
       "NA19703  African ancestry in SW USA  \n",
       "...                             ...  \n",
       "NA19119    Yoruba in Ibadan Nigeria  \n",
       "NA18860    Yoruba in Ibadan Nigeria  \n",
       "NA19207    Yoruba in Ibadan Nigeria  \n",
       "NA19103    Yoruba in Ibadan Nigeria  \n",
       "NA19099    Yoruba in Ibadan Nigeria  \n",
       "\n",
       "[1184 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_dict = {'ASW':'African ancestry in SW USA',\n",
    "            'CEU':'Utah residents with N and W European ancestry',\n",
    "            'CHB':'Han Chinese in Beijing China',\n",
    "            'CHD':'Chinese in Metropolitan Denver Colorado',\n",
    "            'GIH':'Gujarati Indians in Houston Texas',\n",
    "            'JPT':'Japanese in Tokyo Japan',\n",
    "            'LWK':'Luhya in Webuye Kenya',\n",
    "            'MEX':'Mexican ancestry in Los Angeles California',\n",
    "            'MKK':'Maasai in Kinyawa Kenya',\n",
    "            'TSI':'Toscans in Italy',\n",
    "            'YRI':'Yoruba in Ibadan Nigeria'}\n",
    "pheno2 = pheno.replace({\"population\": pop_dict})\n",
    "pheno2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3FL19dojZ1b3"
   },
   "outputs": [],
   "source": [
    "# TASK Scaling\n",
    "# We need to scale our counts data so that it is bound between 0 and 1.\n",
    "\n",
    "geno_data = data/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YkdzkQeUaX9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of individuals: 947\n",
      "\t - training set:          rs416967  rs17013842  rs13052452  rs11049986  rs10994341  rs1504289  \\\n",
      "NA18542       0.5         0.0         0.5         0.0         0.0        0.5   \n",
      "NA20753       0.0         0.0         0.0         0.0         0.0        0.0   \n",
      "\n",
      "         rs882529  rs3885937  rs537330  rs9372090  ...  rs1558766  rs7818288  \\\n",
      "NA18542       0.0        0.0       0.5        1.0  ...        0.0        0.5   \n",
      "NA20753       0.0        0.0       0.0        0.5  ...        0.0        0.0   \n",
      "\n",
      "         rs1051685  rs11223492  rs789492  rs6557516  rs7313246  rs317892  \\\n",
      "NA18542        0.0         0.0       0.0        0.0        0.5       0.0   \n",
      "NA20753        0.0         0.0       0.0        0.0        0.0       1.0   \n",
      "\n",
      "         rs11937009  rs2806497  \n",
      "NA18542         0.0        0.0  \n",
      "NA20753         0.0        0.0  \n",
      "\n",
      "[2 rows x 5000 columns]\n",
      "\t - test set:          rs416967  rs17013842  rs13052452  rs11049986  rs10994341  rs1504289  \\\n",
      "NA19916       0.5         0.0         0.0         0.5         0.5        0.0   \n",
      "NA19914       0.0         0.0         0.5         0.5         0.0        0.5   \n",
      "\n",
      "         rs882529  rs3885937  rs537330  rs9372090  ...  rs1558766  rs7818288  \\\n",
      "NA19916       0.5        0.5       1.0        0.5  ...        0.0        0.0   \n",
      "NA19914       0.0        0.5       0.5        0.5  ...        0.0        1.0   \n",
      "\n",
      "         rs1051685  rs11223492  rs789492  rs6557516  rs7313246  rs317892  \\\n",
      "NA19916        0.0         0.0       0.0        0.5        0.5       0.5   \n",
      "NA19914        0.0         0.0       0.0        0.0        0.5       0.0   \n",
      "\n",
      "         rs11937009  rs2806497  \n",
      "NA19916         0.5        0.0  \n",
      "NA19914         0.0        0.0  \n",
      "\n",
      "[2 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "# TASK Randomly split into the training and the validation set, so that 80 per-cent of individuals ends up in the training set.\n",
    "\n",
    "train = geno_data.sample(frac = 0.8, random_state = 42)\n",
    "test = geno_data.drop(train.index)\n",
    "train.reset_index()\n",
    "test.reset_index()\n",
    "\n",
    "# TASK Print some info about the resulting split\n",
    "print(\"Total number of individuals:\", train.shape[0])\n",
    "print(\"\\t - training set:\", train.head(2))\n",
    "print(\"\\t - test set:\", test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZU4jM1w8dG0D",
    "outputId": "a09953a8-5889-432d-8270-85d3758c790b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5000)]            0         \n",
      "                                                                 \n",
      " layer1 (Dense)              (None, 1500)              7501500   \n",
      "                                                                 \n",
      " layer2 (BatchNormalization)  (None, 1500)             6000      \n",
      "                                                                 \n",
      " layer3 (Dropout)            (None, 1500)              0         \n",
      "                                                                 \n",
      " layer4 (Dense)              (None, 250)               375250    \n",
      "                                                                 \n",
      " layer5 (Dropout)            (None, 250)               0         \n",
      "                                                                 \n",
      " layer6 (Dense)              (None, 25)                6275      \n",
      "                                                                 \n",
      " layer_bottleneck (Dense)    (None, 2)                 52        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25)                75        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               6500      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 250)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1500)              376500    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5000)              7505000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,777,152\n",
      "Trainable params: 15,774,152\n",
      "Non-trainable params: 3,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TASK Specify the autoencoder model\n",
    "\n",
    "train_tensor = train.to_numpy()\n",
    "print(type(train_tensor))\n",
    "\n",
    "# TASK Hyperparameters\n",
    "# use ReLu activations, ADAM optimizer and\n",
    "# mean squared error as the loss function\n",
    "hp_loss_fn = \"mse\"\n",
    "hp_act_fn = \"relu\"\n",
    "hp_optimizer = \"adam\"\n",
    "hp_metrics = ['mse','mae','mape']\n",
    "\n",
    "input_data = keras.Input(shape = (train_tensor.shape[1],))\n",
    "\n",
    "# TASK Define architecture of the encoder:\n",
    "# the second layer should be a batch normalization\n",
    "\n",
    "def Encoder(input):\n",
    "  # Encoder\n",
    "  layer1 = layers.Dense(units = 1500, activation = hp_act_fn, name='layer1')(input)\n",
    "  layer2 = layers.BatchNormalization()(layer1)\n",
    "  layer3 = layers.Dropout(rate = 0.05, name='layer3')(layer2)\n",
    "  layer4 = layers.Dense(units = 250, activation = hp_act_fn, name='layer4')(layer3)\n",
    "  layer5 = layers.Dropout(rate = 0.025, name='layer5')(layer4)\n",
    "  layer6 = layers.Dense(units = 25, activation = hp_act_fn, name='layer6')(layer5)\n",
    "  bottleneck = layers.Dense(units = 2, name='layer_bottleneck')(layer6)\n",
    "  return(bottleneck)\n",
    "\n",
    "# TASK Look at the encoder, complete the decoder function\n",
    "\n",
    "def Decoder(bottleneck):\n",
    "  # Decoder\n",
    "  layer7 = layers.Dense(units = 25, activation = hp_act_fn)(bottleneck)\n",
    "  layer8=l\n",
    "  layer12 = layers.Dense(units = train_tensor.shape[1], activation = 'sigmoid')(layer11)\n",
    "  return(layer12)\n",
    "\n",
    "def Autoencoder(input):\n",
    "  enc = Encoder(input)\n",
    "  autoenc = Decoder(enc)\n",
    "  return(autoenc)\n",
    "\n",
    "autoencoder_model = keras.Model(inputs = input_data, outputs = Autoencoder(input_data))\n",
    "autoencoder_model.compile(\n",
    "  loss = hp_loss_fn,\n",
    "  optimizer = hp_optimizer,\n",
    "  metrics = hp_metrics\n",
    ")\n",
    "\n",
    "# TASK Visualise the created architecture and summarise its parameters\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tfb6ey7bndRc"
   },
   "outputs": [],
   "source": [
    "# TASK Set hyperparameters for model fitting\n",
    "# Begin by training for 30 epochs, with mini-batch of 256 and validation set\n",
    "# having 20 per-cent of examples\n",
    "\n",
    "...\n",
    "\n",
    "autoencoder = autoencoder_model.fit(x = train_tensor,\n",
    "                      y = train_tensor,\n",
    "                      epochs = hp_epochs,\n",
    "                      batch_size = hp_batch_size,\n",
    "                      shuffle = True,\n",
    "                      validation_split = hp_val_split,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwdEFIC1cFPb"
   },
   "source": [
    "Now, let us look at the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9bm8NQGMzqM"
   },
   "outputs": [],
   "source": [
    "loss = autoencoder.history['loss']\n",
    "val_loss = autoencoder.history['val_loss']\n",
    "epochs = range(hp_epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4Qn_e2QcLQL"
   },
   "source": [
    "Now, that the model is trained, we can save the weights and use them to build an encoder. Note that weights are saved for the entire autoencoder, so we need to use `skip_mismatch = True` along with `by_name = True` to initialize weights in our encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cwxgo-HPRSn"
   },
   "outputs": [],
   "source": [
    "autoencoder_model.save_weights('autoencoder_weights.weights.h5',\n",
    "                               overwrite = True)\n",
    "\n",
    "encoder_model = keras.Model(inputs = input_data, outputs = Encoder(input_data))\n",
    "encoder_model.load_weights('autoencoder_weights.weights.h5',\n",
    "                           skip_mismatch = True)\n",
    "encoder_model.compile(\n",
    "  loss = hp_loss_fn,\n",
    "  optimizer = hp_optimizer,\n",
    "  metrics = hp_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhDovZnxcpiS"
   },
   "source": [
    "Let us embed our genotyping data using the encoder we have just constructed.\n",
    "We can also visualise the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfJ1GMyZST6N"
   },
   "outputs": [],
   "source": [
    "embeded_points = encoder_model.predict(geno_data.to_numpy())\n",
    "print(embeded_points)\n",
    "\n",
    "x = embeded_points[:,0]\n",
    "y = embeded_points[:,1]\n",
    "pop = pheno2['population']\n",
    "data = {'x':x, 'y':y, 'pop':pop}\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.scatterplot(x='x', y='y', data=data, hue='pop', style='pop', s=100)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0, markerscale=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cu093dtc3V8"
   },
   "source": [
    "Now, we will compare the result with:\n",
    "* MDS on the kinship matrix\n",
    "* PCA perfored directly on raw genotypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wncBFt7pl77e"
   },
   "outputs": [],
   "source": [
    "kinship = pd.read_csv(\"autosomal_5k_kinship.csv\", header=0, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd1JVviGiTFL",
    "outputId": "ada0200b-94ad-4087-e7d2-3d7d494c9c84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_mds.py:419: UserWarning: The MDS API has changed. ``fit`` now constructs an dissimilarity matrix from data. To use a custom dissimilarity matrix, set ``dissimilarity='precomputed'``.\n",
      "  warnings.warn(\"The MDS API has changed. ``fit`` now constructs an\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import MDS\n",
    "embedding = MDS(n_components=2)\n",
    "mds_embedding = embedding.fit_transform(kinship)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "guuTDjHaiuZ6"
   },
   "outputs": [],
   "source": [
    "# TASK Plot MDS embedding in a way similar to plotting autoencoder embeddings\n",
    "x = ...\n",
    "y = ...\n",
    "data = {'x':x, 'y':y, 'pop':pop}\n",
    "plt.figure(figsize = (10,10))\n",
    "...\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_MYJAJ8deKh"
   },
   "source": [
    "Finally, we will perform PCA on raw genotypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZznrf_q1gE2"
   },
   "outputs": [],
   "source": [
    "# TASK perform PCA with 2 components on raw genotypes (use geno_data as input but remember it has been scaled)\n",
    "# Visualise the result.\n",
    "from sklearn.decomposition import PCA\n",
    "embedding = PCA(...)\n",
    "pca_embedding = ...\n",
    "...\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0, markerscale=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
